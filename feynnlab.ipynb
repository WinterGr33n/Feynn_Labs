{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.decomposition import PCA\n",
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "from bioinfokit.visuz import cluster\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.utils import resample\n",
    "from sklearn.metrics import adjusted_rand_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_csv(\"mcdonalds.csv\")\n",
    "data1=pd.read_csv(\"mcdonalds.csv\")\n",
    "data.columns.values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MD=data.iloc[:,0:11].replace(\"Yes\",1).replace(\"No\",0)\n",
    "mean=round(MD.mean(),2)\n",
    "mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "pca = PCA()\n",
    "MD_pca=pca.fit_transform(MD)\n",
    "MD_p=pca.fit(MD)\n",
    "\n",
    "SD=np.sqrt(pca.explained_variance_)\n",
    "PV=pca.explained_variance_ratio_\n",
    "index=[]\n",
    "for i in range(len(SD)):\n",
    "    i=i+1\n",
    "    index.append(\"PC{}\".format(i))\n",
    "\n",
    "sum=pd.DataFrame({\n",
    "    \"Standard deviation\":SD,\"Proportion of Variance\":PV,\"Cumulative Proportion\":PV.cumsum()\n",
    "},index=index)\n",
    "sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Standard Deviation:\\n\",SD.round(1))\n",
    "\n",
    "load = (pca.components_)\n",
    "i=0\n",
    "rot_matrix = MD_p.components_.T\n",
    "\n",
    "rot_df = pd.DataFrame(rot_matrix, index=MD.columns.values, columns=index)\n",
    "rot_df=round(-rot_df,3)\n",
    "rot_df\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rot_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "cluster.biplot(cscore=MD_pca, loadings=-load, labels=data.columns.values,var1=0,var2=0, show=True, dim=(10, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "np.random.seed(1234)\n",
    "\n",
    "nrep = 10\n",
    "\n",
    "num_segments = range(1, 9)\n",
    "within_cluster_distances = []\n",
    "MD_km28 = {}\n",
    "\n",
    "for k in num_segments:\n",
    "    kmeans = KMeans(n_clusters=k, n_init=nrep, random_state=1234)\n",
    "    kmeans.fit(MD)\n",
    "    within_cluster_distances.append((kmeans.inertia_))\n",
    "    MD_km28[str(k)] = kmeans\n",
    "\n",
    "plt.bar(num_segments, within_cluster_distances)\n",
    "plt.xlabel(\"Number of segments\")\n",
    "plt.ylabel(\"Sum of within-cluster distances\")\n",
    "plt.title(\"Segmentation Results\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "np.random.seed(1234) \n",
    "nboot = 100  \n",
    "nrep = 10  \n",
    "\n",
    "bootstrap_samples = []\n",
    "for _ in range(nboot):\n",
    "    bootstrap_sample = resample(MD.values, random_state=1234) \n",
    "    bootstrap_samples.append(bootstrap_sample)\n",
    "\n",
    "adjusted_rand_index = []\n",
    "num_segments = range(2, 9)\n",
    "for k in num_segments:\n",
    "    stability_scores = []\n",
    "    for bootstrap_sample in bootstrap_samples:\n",
    "        kmeans = KMeans(n_clusters=k, n_init=nrep, random_state=1234)  \n",
    "        kmeans.fit(bootstrap_sample)\n",
    "        cluster_labels = kmeans.predict(bootstrap_sample)\n",
    "        true_labels = kmeans.predict(MD.values)\n",
    "        stability_score = adjusted_rand_score(true_labels, cluster_labels)\n",
    "        stability_scores.append(stability_score)\n",
    "    adjusted_rand_index.append(stability_scores)\n",
    "\n",
    "# Transpose the adjusted_rand_index list\n",
    "adjusted_rand_index = np.array(adjusted_rand_index).T\n",
    "\n",
    "# Create boxplot of adjusted Rand index\n",
    "plt.boxplot(adjusted_rand_index, labels=num_segments, whis=10)\n",
    "plt.xlabel(\"Number of segments\")\n",
    "plt.ylabel(\"Adjusted Rand Index\")\n",
    "plt.title(\"Bootstrap Flexclust\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "range_values = (0, 1)\n",
    "num_bins = 10\n",
    "max_frequency = 200\n",
    "\n",
    "\n",
    "fig, axs = plt.subplots(2, 2, figsize=(12, 8))\n",
    "\n",
    "\n",
    "for i in range(1, 5):\n",
    "    labels = MD_km28[str(i)].predict(MD)\n",
    "    similarities = MD_km28[str(i)].transform(MD).min(axis=1)\n",
    "    row = (i - 1) // 2\n",
    "    col = (i - 1) % 2\n",
    "\n",
    "    axs[row, col].hist(similarities, bins=num_bins, range=range_values)\n",
    "    axs[row, col].set_xlabel('Similarity')\n",
    "    axs[row, col].set_ylabel('Frequency')\n",
    "    axs[row, col].set_title('cluster {}'.format(i))\n",
    "\n",
    "    axs[row, col].set_xlim(range_values)\n",
    "    axs[row, col].set_ylim(0, max_frequency)\n",
    "\n",
    "\n",
    "    axs[row, col].set_xticks([0, 0.2, 0.4, 0.6, 0.8, 1.0])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "num_segments = range(2, 9)\n",
    "\n",
    "segment_stability = []\n",
    "for segment in range(2, 9):\n",
    "    labels_segment = MD_km28[str(segment)].predict(MD)\n",
    "    segment_stability.append(labels_segment)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "for i, segment in enumerate(range(2, 9)):\n",
    "    plt.plot(num_segments, [np.mean(segment_stability[i] == labels) for labels in segment_stability], marker='o', label=f'Segment {segment}')\n",
    "\n",
    "plt.xlabel('Number of Segments')\n",
    "plt.ylabel('Segment Level Stability')\n",
    "plt.title('Segment Level Stability Across Solutions (SLSA) Plot')\n",
    "plt.xticks(num_segments)\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "segment_solutions = [\"2\", \"3\", \"4\", \"5\"]\n",
    "segment_labels = {}\n",
    "segment_similarities = {}\n",
    "\n",
    "for segment in segment_solutions:\n",
    "    segment_labels[segment] = MD_km28[segment].predict(MD)\n",
    "    segment_similarities[segment] = MD_km28[segment].transform(MD).min(axis=1)\n",
    "\n",
    "segment_stability_values = []\n",
    "for segment in segment_solutions:\n",
    "    similarities = segment_similarities[segment]\n",
    "    normalized_similarities = similarities / np.max(similarities) \n",
    "    segment_stability_values.append(normalized_similarities)\n",
    "\n",
    "plt.boxplot(segment_stability_values, whis=1.5)\n",
    "plt.xlabel(\"Segment Number\")\n",
    "plt.ylabel(\"Segment Stability\")\n",
    "plt.xticks(range(1, len(segment_solutions) + 1), segment_solutions)\n",
    "plt.ylim(0, 1)\n",
    "plt.title(\"Segment Level Stability within Solutions\")\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import entropy\n",
    "\n",
    "np.random.seed(1234)\n",
    "k_values = range(2, 9)\n",
    "MD_m28 = []\n",
    "\n",
    "for k in k_values:\n",
    "    model = KMeans(n_clusters=k, random_state=1234)\n",
    "    model.fit(MD.values)\n",
    "    iter_val = model.n_iter_\n",
    "    converged = True\n",
    "    k_val = k\n",
    "    k0_val = k\n",
    "    log_likelihood = -model.inertia_\n",
    "    n_samples, _ = MD.shape\n",
    "    aic = -2 * log_likelihood + 2 * k\n",
    "    bic = -2 * log_likelihood + np.log(n_samples) * k\n",
    "    labels = model.labels_\n",
    "    counts = np.bincount(labels)\n",
    "    probs = counts / float(counts.sum())\n",
    "    class_entropy = entropy(probs)\n",
    "    icl = bic - class_entropy\n",
    "    \n",
    "    MD_m28.append((iter_val, converged, k_val, k0_val, log_likelihood, aic, bic, icl))\n",
    "MD_m28 = pd.DataFrame(MD_m28, columns=['iter', 'converged', 'k', 'k0', 'logLik', 'AIC', 'BIC', 'ICL'])\n",
    "\n",
    "print(MD_m28)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_segments = MD_m28[\"k\"]\n",
    "AIC_values = MD_m28[\"AIC\"]\n",
    "BIC_values = MD_m28[\"BIC\"]\n",
    "ICL_values = MD_m28[\"ICL\"]\n",
    "\n",
    "plt.plot(num_segments, AIC_values, marker='o', label='AIC')\n",
    "plt.plot(num_segments, BIC_values, marker='o', label='BIC')\n",
    "plt.plot(num_segments, ICL_values, marker='o', label='ICL')\n",
    "\n",
    "plt.xlabel('Number of Segments')\n",
    "plt.ylabel('Value of Information Criteria')\n",
    "plt.title('Information Criteria (AIC, BIC, ICL)')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.mixture import GaussianMixture\n",
    "k = 4\n",
    "kmeans = KMeans(n_clusters=k, random_state=1234)\n",
    "kmeans.fit(MD)\n",
    "kmeans_clusters = kmeans.predict(MD)\n",
    "\n",
    "gmm = GaussianMixture(n_components=k, random_state=1234)\n",
    "gmm.fit(MD)\n",
    "gmm_clusters = gmm.predict(MD)\n",
    "\n",
    "results = pd.DataFrame({'kmeans': kmeans_clusters, 'mixture': gmm_clusters})\n",
    "\n",
    "MD_m4 = MD[results['mixture'] == 3] \n",
    "\n",
    "k4_m4 = KMeans(n_clusters=k, random_state=1234)\n",
    "k4_m4.fit(MD_m4)\n",
    "k4_m4_clusters = k4_m4.predict(MD_m4)\n",
    "\n",
    "results_m4 = pd.DataFrame({'kmeans': k4_m4_clusters, 'mixture': 3})\n",
    "\n",
    "print(pd.crosstab(results['kmeans'], results['mixture']))\n",
    "print(pd.crosstab(results['kmeans'], results_m4['kmeans']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.mixture import GaussianMixture\n",
    "import numpy as np\n",
    "\n",
    "gmm_m4a = GaussianMixture(n_components=4)\n",
    "gmm_m4a.fit(MD)\n",
    "\n",
    "log_likelihood_m4a = gmm_m4a.score(MD)\n",
    "\n",
    "gmm_m4 = GaussianMixture(n_components=4)\n",
    "gmm_m4.fit(MD)\n",
    "\n",
    "log_likelihood_m4 = gmm_m4.score(MD)\n",
    "\n",
    "print(\"Log-likelihood for MD.m4a:\", log_likelihood_m4a)\n",
    "print(\"Log-likelihood for MD.m4:\", log_likelihood_m4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "like_counts = pd.value_counts(data['Like'])\n",
    "reversed_counts = like_counts.iloc[::-1]\n",
    "\n",
    "print(reversed_counts)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a mapping of string values to numeric codes\n",
    "like_mapping = {\n",
    "    'I HATE IT!-5': -5,\n",
    "    '-4': -4,\n",
    "    '-3': -3,\n",
    "    '-2': -2,\n",
    "    '-1': -1,\n",
    "    '0': 0,\n",
    "    '1': 1,\n",
    "    '2': 2,\n",
    "    '3': 3,\n",
    "    '4': 4,\n",
    "    'I LOVE IT!+5': 5\n",
    "}\n",
    "\n",
    "data['Like.n'] = data['Like'].map(like_mapping)\n",
    "\n",
    "\n",
    "like_n_counts = data['Like.n'].value_counts()\n",
    "\n",
    "\n",
    "print(like_n_counts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from patsy import dmatrices\n",
    "\n",
    "independent_vars = data.columns[0:11] \n",
    "\n",
    "formula_str = ' + '.join(independent_vars)\n",
    "\n",
    "formula_str = 'Like ~ ' + formula_str\n",
    "\n",
    "\n",
    "f = dmatrices(formula_str, data=data)[1]\n",
    "\n",
    "print(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.mixture import GaussianMixture\n",
    "from patsy import dmatrix\n",
    "np.random.seed(1234)\n",
    "\n",
    "X = dmatrix(f.design_info, data=data)\n",
    "y = dmatrix('Like', data=data)\n",
    "\n",
    "n_components = 2\n",
    "n_init = 10\n",
    "verbose = False\n",
    "n_rep=10\n",
    "\n",
    "model = GaussianMixture(n_components=n_components, n_init=n_init, verbose=verbose)\n",
    "MD_reg2 = model.fit(X, y)\n",
    "\n",
    "print(MD_reg2)\n",
    "cluster_sizes = np.bincount(model.predict(X))\n",
    "\n",
    "print(\"Cluster sizes:\")\n",
    "for i, size in enumerate(cluster_sizes):\n",
    "    print(f\"{i+1}: {size}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------------------------------------\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "kmeans = MD_km28['4']\n",
    "\n",
    "labels = kmeans.labels_\n",
    "\n",
    "MD_mean = MD.groupby(labels).mean()\n",
    "\n",
    "fig, axs = plt.subplots(2, 2, figsize=(10, 6))\n",
    "axs[0, 0].barh(range(MD_mean.shape[1]), MD_mean.iloc[0])\n",
    "axs[0, 0].set_title('Component 1')\n",
    "axs[0, 1].barh(range(MD_mean.shape[1]), MD_mean.iloc[1])\n",
    "axs[0, 1].set_title('Component 2')\n",
    "axs[1, 0].barh(range(MD_mean.shape[1]), MD_mean.iloc[2])\n",
    "axs[1, 0].set_title('Component 3')\n",
    "axs[1, 1].barh(range(MD_mean.shape[1]), MD_mean.iloc[3])\n",
    "axs[1, 1].set_title('Component 4')\n",
    "\n",
    "for ax in axs.flat:\n",
    "    ax.set(ylabel='Variable', xlabel='Proportion')\n",
    "    ax.set_yticks(range(MD_mean.shape[1]))\n",
    "    ax.set_yticklabels(MD.columns)\n",
    "\n",
    "for ax in axs.flat:\n",
    "    ax.label_outer()\n",
    "\n",
    "fig.suptitle('Segment Profiles')\n",
    "\n",
    "fig.tight_layout()\n",
    "\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "kmeans = KMeans(n_clusters=4)\n",
    "kmeans.fit(MD)\n",
    "\n",
    "pca = PCA(n_components=2)\n",
    "MD_pca = pca.fit_transform(MD)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "ax.scatter(MD_pca[:, 0], MD_pca[:, 1])\n",
    "ax.set_xlabel('principal component 1')\n",
    "ax.set_ylabel('principal component 2')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.graphics.mosaicplot import mosaic\n",
    "from itertools import product\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.cluster import KMeans\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Label encoding for categorical - Converting 11 cols with yes/no\n",
    "def labelling(x):\n",
    "    data1[x] = LabelEncoder().fit_transform(data1[x])\n",
    "    return data1\n",
    "\n",
    "cat = ['yummy', 'convenient', 'spicy', 'fattening', 'greasy', 'fast', 'cheap',\n",
    "       'tasty', 'expensive', 'healthy', 'disgusting']\n",
    "\n",
    "for i in cat:\n",
    "    labelling(i)\n",
    "\n",
    "df_eleven = data1.loc[:, cat]\n",
    "\n",
    "kmeans = KMeans(n_clusters=4, init='k-means++', random_state=0).fit(df_eleven)\n",
    "data1['cluster_num'] = kmeans.labels_ \n",
    "\n",
    "crosstab = pd.crosstab(data1['cluster_num'], data1['Like'])\n",
    "\n",
    "# Define the desired order\n",
    "desired_order = ['I hate it!-5', '-4', '-3', '-2', '-1', '0', '1', '2', '3', '4', 'I love it!+5']\n",
    "\n",
    "# Reorder columns, including only those that exist\n",
    "existing_cols = [col for col in desired_order if col in crosstab.columns]\n",
    "crosstab = crosstab[existing_cols]\n",
    "\n",
    "plt.rcParams['figure.figsize'] = (7,5)\n",
    "mosaic(crosstab.stack())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.graphics.mosaicplot import mosaic\n",
    "\n",
    "MD_k4=MD_km28['4']\n",
    "k4 = MD_k4.labels_\n",
    "\n",
    "ct = pd.crosstab(k4, data['Gender'])\n",
    "ct\n",
    "mosaic(ct.stack(),gap=0.01)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'Segment': k4, 'Age': data['Age']})\n",
    "\n",
    "df.boxplot(by='Segment', column='Age')\n",
    "plt.title('Parallel box-and-whisker plot of age by segment')\n",
    "plt.suptitle('')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1['VisitFrequency'] = LabelEncoder().fit_transform(data1['VisitFrequency'])\n",
    "visit = data1.groupby('cluster_num')['VisitFrequency'].mean()\n",
    "visit = visit.to_frame().reset_index()\n",
    "visit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Like\n",
    "data1['Like'] = LabelEncoder().fit_transform(data1['Like'])\n",
    "Like = data1.groupby('cluster_num')['Like'].mean()\n",
    "Like = Like.to_frame().reset_index()\n",
    "Like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1['Gender'] = LabelEncoder().fit_transform(data1['Gender'])\n",
    "Gender = data1.groupby('cluster_num')['Gender'].mean()\n",
    "Gender = Gender.to_frame().reset_index()\n",
    "Gender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "segment = Gender.merge(Like, on='cluster_num', how='left').merge(visit, on='cluster_num', how='left')\n",
    "segment\n",
    "plt.figure(figsize = (9,4))\n",
    "sns.scatterplot(x = \"VisitFrequency\", y = \"Like\",data=segment,s=400, color=\"r\")\n",
    "plt.title(\"Simple segment evaluation plot for the fast food data set\",fontsize = 15) \n",
    "plt.xlabel(\"Visit\", fontsize = 12) \n",
    "plt.ylabel(\"Like\", fontsize = 12) \n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
